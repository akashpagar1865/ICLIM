
# ICLIM â€” Intelligent Cloud-Linux Infrastructure Monitor

*ICLIM is a Python-based system and log monitoring project built to reflect real-world Cloud/SRE
engineering practices â€” including Azure deployment, systemd services, CI/CD automation, and anomaly detection..*

## Overview

ICLIM is a self-built Linux system observability and automation project, designed to simulate real-world infrastructure monitoring workflows on cloud Linux VMs. It collects system metrics, detects anomalies using AI
models, and produces visual insights â€” all built incrementally to mirror industry practices in SRE, monitoring, and cloud operations.

===================================================================================================================

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        Linux VM           â”‚
            â”‚ (Local / Azure / CentOS)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  system metrics + logs
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        Live Agent         â”‚
            â”‚  (CPU / MEM / DISK)       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  periodic snapshots
                        â–¼
                snapshot_history.jsonl
                        â”‚
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Anomaly Training      â”‚
            â”‚ (baseline behavior model) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  anomaly_model.pkl
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Realtime Anomaly Agent   â”‚
            â”‚ (detects deviations)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  anomaly events
                        â–¼
                anomaly_events.jsonl


            =========================================================
                            PHASE 2 â€” LOG INTELLIGENCE
            =========================================================

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      System Logs          â”‚
            â”‚  (/var/log/messages,     â”‚
            â”‚   sshd, systemd, etc.)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚
                        â–¼
                    clean_log_line()
            (timestamp / host / PID removal)
                        â”‚
                        â”‚
                        â–¼
                TF-IDF Vectorization
                        â”‚
                        â”‚
                        â–¼
            Logistic Regression Model
                        â”‚
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Log Classification      â”‚
            â”‚  info / warning / error   â”‚
            â”‚        / security         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  summaries + alerts
                        â–¼
                classification_summary


            =========================================================
                            PHASE 3 â€” VISUALIZATION
            =========================================================

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Dashboard Generator     â”‚
            â”‚ (generate_dashboard.py)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  matplotlib charts
                        â–¼
                PNG Charts (CPU, MEM,
                    DISK, anomalies)
                        â”‚
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    HTML Dashboard         â”‚
            â”‚     index.html            â”‚
            â”‚  (static, portable)      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚
                        â–¼
                    GitHub Pages /
                    Local Browser


            =========================================================
                        PHASE 4 â€” AUTOMATION & CLOUD
            =========================================================

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     GitHub Actions        â”‚
            â”‚ (scheduled workflows)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  run agents + analysis
                        â–¼
                    Artifacts / Reports
                        â”‚
                        â”‚
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        Azure Cloud        â”‚
            â”‚  Linux VM + Blob Storage â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


===================================================================================================================

## Core Capabilities (Current + Upcoming)

## â˜ï¸ Cloud Deployment

This project has been successfully deployed on an Azure Ubuntu VM, configured with secure access and persistent services using systemd. CI pipelines validate changes before deployment.

### âœ… Completed

  * Python fundamentals (functions, data structures, modules)
  * File handling (text + JSON)
  * Structured system snapshots
  * Live metric collection using `psutil` (CPU, memory, disk)
  * JSON-based data pipeline foundation
  * Timestamped metric collection
  * Loaded and analyzed historical snapshots using pandas
  * AI-based anomaly detection using IsolationForest (model saved as `anomaly_model.pkl`)
  * Real-time anomaly detection using the trained AI model
  * Retraining pipeline that:
    * uses recent snapshots from `snapshot_history.jsonl`
    * safely skips invalid JSON lines
    * can exclude known anomalies from training
  * Log classification pipeline (TF-IDF + Logistic Regression) for INFO / WARNING / ERROR / SECURITY
  * Lightweight HTML dashboard with .png charts
  * Deployed realtime anomaly agent as systemd service on CentOS
  * CI/CD pipeline validated using GitHub Actions (Python 3.9, Linux runner)
  * Deployed and managed as a **systemd service** on an **Azure Ubuntu VM**
  * CI validation with GitHub Actions
  * Persistent service startup across reboots
  * Real-world Linux troubleshooting (SELinux, service failures)

===================================================================================================================

## ğŸ›  Tech Stack

Component          Tools
------------------ -------------------------------------
Language           Python
Metrics            psutil
Data Format        JSON / JSONL
AI/ML              scikit-learn (IsolationForest), TF-IDF
Analysis           pandas
Model Persistence  joblib
Dashboard          HTML + PNG charts
Linux VM (CentOS)  Systemd service
CI/CD Pipeline     Git Hub Actions 
Cloud Integration  Azure VM

===================================================================================================================

## ğŸ“‚ System Architecture

    ICLIM/
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ live_agent.py
    â”‚   â”œâ”€â”€ snapshot_agent.py
    â”‚   â”œâ”€â”€ realtime_anomaly_agent.py
    â”‚   â””â”€â”€ history_logger.py
    â”‚
    â”œâ”€â”€ analysis/
    â”‚   â”œâ”€â”€ log_classifier.py
    â”‚   â”œâ”€â”€ anomaly_training.py
    â”‚   â”œâ”€â”€ anomaly_retrain.py
    â”‚   â”œâ”€â”€ history_analysis.py
    â”‚   â”œâ”€â”€ dashboard_utils.py
    â”‚   â””â”€â”€ generate_dashboard.py
    â”‚
    â”œâ”€â”€ dashboard/
    â”‚   â”œâ”€â”€ index.html
    â”‚   â””â”€â”€ charts/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ snapshot_history.jsonl
    â”‚   â”œâ”€â”€ anomaly_events.jsonl
    â”‚   â”œâ”€â”€ centos_logs.txt
    â”‚   â””â”€â”€ simulated_logs.txt     
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ log_classifier.pkl
    â”‚   â””â”€â”€ anomaly_model.pkl
    â”‚
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ .gitignore


===================================================================================================================

## ğŸš€ Getting Started - Run Instructions

This section explains how to run ICLIM locally or on a Linux VM.

âœ… Prerequisites

Linux or macOS environment (tested on Ubuntu)

Python 3.9+

git

Basic familiarity with terminal commands

Note: The project is designed to mirror real Linux/cloud environments and works best on a Linux VM.

ğŸ“¦ Clone the Repository
git clone https://github.com/akashpagar1865/ICLIM.git
cd ICLIM

ğŸ Create and Activate Virtual Environment
python3 -m venv .venv
source .venv/bin/activate


Upgrade pip and install dependencies:

pip install --upgrade pip
pip install -r requirements.txt

â–¶ï¸ Run Snapshot Monitoring Agent (One-Time)

The snapshot agent collects a point-in-time view of system metrics.

python agents/snapshot_agent.py


Expected outcome:

System metrics are collected

Output files are generated in the data/output directory

ğŸ” Run Realtime Monitoring Agent (Continuous)

The realtime agent runs continuously and simulates a long-running production service.

python agents/realtime_agent.py


Expected behavior:

Agent runs in a loop

Periodically collects metrics and logs

Designed to be managed via systemd in production setups

ğŸ“Š Generate Dashboard

Once data is collected, generate the visualization dashboard:

python dashboard/generate_dashboard.py


This produces:

Graphs and summaries based on collected metrics

A simple visual representation of system behavior

âš™ï¸ (Optional) Run as a systemd Service (Linux)

To simulate production-style deployment, the realtime agent can be configured as a systemd service.

High-level steps:

Create a systemd service file

Point it to the virtualenv Python binary

Enable and start the service

This allows the agent to:

Start automatically on boot

Recover after reboots or crashes

Detailed systemd configuration is documented separately.


ğŸ§ª Typical Execution Flow (Quick Reference)

For a first-time run:

Clone repo

Create virtual environment

Run snapshot agent

Run realtime agent

Generate dashboard


ğŸ›‘ Stopping the Agents

Press CTRL + C to stop agents running in the foreground

For systemd-managed services, use:

sudo systemctl stop iclim.service


===================================================================================================================

## ğŸ¯ Learning Goals

This project supports my transition into:

* Linux system administration
* Cloud infrastructure operations
* Automation and monitoring
* DevOps/SRE-style tooling
* AI-assisted observability

Each component is added incrementally, with commits and documentation reflecting real engineering workflow.

ğŸ‘¨â€ğŸ’» Why I Built This
This project was constructed to mirror infrastructure and observability work done in Cloud and SRE roles. Each commit reflects a real-world milestone: from Linux metric collection to failure handling and resilience.

===================================================================================================================

## ğŸ“ˆ Roadmap Overview

```
[âœ“] Python fundamentals
[âœ“] JSON snapshot pipeline
[âœ“] Live metric collector
[âœ“] Timestamped data collection
[âœ“] Historical dataset builder
[âœ“] AI anomaly detector
[âœ“] Real-time anomaly detection + retraining pipeline
[âœ“] NLP log classifier
[âœ“] HTML dashboard
[âœ“] Linux deployment
[âœ“] Cloud deployment (Azure)
[âœ“] CI/CD automation
```

===================================================================================================================

## ğŸ¤ Contributions & Feedback

This is a learning-first project, but feedback, suggestions, or guidance from the community are welcome â€” especially around Linux automation, Azure deployment, and ML-based observability.

---

## ğŸ“¬ Contact

If youâ€™d like to connect professionally or discuss cloud/infra engineering roles:

**LinkedIn:** [https://www.linkedin.com/in/akash-pagar-23316816b/](https://www.linkedin.com/in/akash-pagar-23316816b/)
**GitHub:** [https://github.com/akashpagar1865](https://github.com/akashpagar1865)

---

